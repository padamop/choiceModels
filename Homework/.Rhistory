1.73173, 1.70444, 1.70634, 1.72684, 1.72018,
1.74533, 1.73528, 1.73403, 1.74428, 1.73907,
1.69839, 1.69338, 1.70259, 1.71237, 1.69951),
Evaluation = c(1.81341, 1.80974, 1.80839, 1.82471, 1.81603, 1.81341, 1.81678, 1.82292, 1.8275, 1.81392, 1.81341, 1.81963, 1.82303, 1.82869, 1.8139, 1.74533, 1.73388, 1.73274, 1.74421, 1.74027, 1.74533, 1.73528, 1.73403, 1.74428, 1.73907, 1.74533, 1.7357, 1.73419, 1.74461, 1.73942, 1.81591, 1.80616, 1.80475, 1.8148, 1.80752, 1.81591, 1.81037, 1.81582, 1.81598, 1.81108, 1.81591, 1.8093, 1.81563, 1.81609, 1.81184, 2.00663, 1.91859, 1.91699, 1.93072, 1.92486, 2.00663, 1.92402, 1.93333, 1.93237, 1.92424, 2.00663, 1.92583, 1.9332, 1.93254, 1.92418, 1.83705, 1.76493, 1.76372, 1.78178, 1.77111, 1.83705, 1.76807, 1.76527, 1.78258, 1.77087, 1.83705, 1.76798, 1.76517, 1.78221, 1.77085, 1.73173, 1.6973, 1.69538, 1.71517, 1.70241, 1.73173, 1.70444, 1.70634, 1.72684, 1.72018, 1.73173, 1.69955, 1.70495, 1.72419, 1.71396, 1.65121, 1.62957, 1.62967, 1.68622, 1.66593, 1.65121, 1.63196, 1.646, 1.6841, 1.66232, 1.65121, 1.62962, 1.64597, 1.6869, 1.66269, 1.57963, 1.56326, 1.56342, 1.59822, 1.58497, 1.57963, 1.56351, 1.56411, 1.5994, 1.58572, 1.57963, 1.56348, 1.56414, 1.60141, 1.5867, 1.64363, 1.61009, 1.6103, 1.64918, 1.6348, 1.64363, 1.60897, 1.61465, 1.6615, 1.65547, 1.64363, 1.60884, 1.6145, 1.66044, 1.6516, 1.74649, 1.72314, 1.73274, 1.76281, 1.74805, 1.74649, 1.72084, 1.73745, 1.76341, 1.74624, 1.74649, 1.72031, 1.73733, 1.76451, 1.74626, 1.69243, 1.67494, 1.67543, 1.7009, 1.69158, 1.69243, 1.67482, 1.67584, 1.69922, 1.68826, 1.69243, 1.67462, 1.67574, 1.70032, 1.68903, 1.74496, 1.71246, 1.7138, 1.74141, 1.73145, 1.74496, 1.71342, 1.71912, 1.75573, 1.75037, 1.74496, 1.71289, 1.71863, 1.75022, 1.7435, 1.63497, 1.5858, 1.59196, 1.629, 1.61118, 1.63497, 1.60275, 1.60785, 1.63166, 1.61127, 1.63497, 1.60249, 1.60782, 1.6347, 1.61167, 1.53216, 1.50188, 1.50206, 1.5296, 1.52182, 1.53216, 1.50271, 1.50282, 1.52945, 1.5188, 1.53216, 1.50254, 1.50289, 1.53184, 1.52061, 1.56667, 1.52841, 1.52867, 1.56503, 1.55347, 1.56667, 1.53682, 1.53953, 1.57918, 1.57124, 1.56667, 1.53517, 1.53904, 1.57396, 1.5675, 1.87141, 1.87386, 1.88229, 1.88178, 1.86411, 1.87141, 1.87874, 1.88898, 1.88221, 1.86217, 1.87141, 1.87609, 1.88866, 1.88401, 1.86242, 1.71455, 1.71439, 1.71469, 1.70629, 1.69736, 1.71455, 1.71502, 1.71541, 1.7044, 1.69394, 1.71455, 1.71488, 1.71538, 1.70686, 1.69576, 1.69839, 1.69282, 1.69345, 1.70597, 1.69672, 1.69839, 1.69338, 1.69814, 1.71286, 1.6986, 1.69839, 1.69338, 1.70259, 1.71237, 1.69951),
1.69243, 1.67462, 1.67574, 1.70032, 1.68903,
source("http://www.r-statistics.com/wp-content/uploads/2010/02/Friedman-Test-with-Post-Hoc.r.txt")  # loading the friedman.test.with.post.hoc function from the internet
### Comparison of five methods ("Wine A", "Wine B", and
###  "Wine C") for rounding first base.
MethodEvaluation <- data.frame(
Evaluation = c(0.79344, 0.79133, 0.7912, 0.79166, 0.79126,
0.79344, 0.79133, 0.7912, 0.79163, 0.7913,
0.78489, 0.78519, 0.78509, 0.78554, 0.78515,
0.78489, 0.78517, 0.78508, 0.78551, 0.78516,
0.82862, 0.82389, 0.8239, 0.82243, 0.82249,
0.82862, 0.82387, 0.82388, 0.82245, 0.82259,
0.81977, 0.81966, 0.81966, 0.81886, 0.81882,
0.81977, 0.81965, 0.81965, 0.81889, 0.81887,
0.81028, 0.81038, 0.81031, 0.8102, 0.81012,
0.81028, 0.81035, 0.81031, 0.81008, 0.81009,
0.80826, 0.8084, 0.80834, 0.80838, 0.80821,
0.80826, 0.80837, 0.80832, 0.8083, 0.80819,
0.81735, 0.81727, 0.81728, 0.81709, 0.81698,
0.81735, 0.81727, 0.81727, 0.81703, 0.81702,
0.81464, 0.81454, 0.81454, 0.81449, 0.81435,
0.81464, 0.81454, 0.81454, 0.81448, 0.81436,
0.82652, 0.82644, 0.82646, 0.82602, 0.82598,
0.82652, 0.82641, 0.82644, 0.82585, 0.82594,
0.82464, 0.82463, 0.82463, 0.82448, 0.82437,
0.82464, 0.82461, 0.82462, 0.82439, 0.82432,
0.89517, 0.89506, 0.89512, 0.88281, 0.88029,
0.89517, 0.89497, 0.89505, 0.88266, 0.87977,
0.89125, 0.8912, 0.89123, 0.88116, 0.87889,
0.89125, 0.89115, 0.89117, 0.88068, 0.8786
),
Methods = factor(rep(c("Baseline", "Hom-Lin", "Hom-Quad", "Het-Lin", "Het-Quad"), 24)),
Baseline = factor(rep(1:24, rep(5, 24))))
with(MethodEvaluation , boxplot( Evaluation  ~ Methods )) # boxploting
Sys.sleep(10)
friedman.test.with.post.hoc(Evaluation ~ Methods | Baseline ,MethodEvaluation)	# the same with our function. With post hoc, and cool plots
View(MethodEvaluation)
View(MethodEvaluation)
library("mlogit")
library("mlogit")
install.packages("mlogit")
library(mlogit)
mlogit
data("TravelMode", package="AER")
install.packages("AER")
head(TravelMode,10)
data("TravelMode", package="AER")
head(TravelMode,10)
TravelMode <- mlogit.data(TravelModem shape="long", choice="choice", alt.var="mode", chid.var="individual")
TravelMode <- mlogit.data(TravelMode, shape="long", choice="choice", alt.var="mode", chid.var="individual")
mnl.TM <- mlogit(choice~gcost+wait | income| TravelMode, reflevel = "car")
mnl.TM <- mlogit(choice~gcost + wait | income, TravelMode, reflevel = "car")
summary(mnl.TM)
mnl_withoutintercept.TM <- mlogit(choice~gcost + wait | income -1, TravelMode, reflevel = "car")
summary(mnl_withoutintercept.TM)
l_.TM <- mlogit(choice~gcost + wait, TravelMode, reflevel = "car", nests = list(fly = "air", ground=c("train", "bus", "car")), unscaled=TRUE)
summary(nl.TM)
summary(l_.TM)
# Choice Models in Operations
# Homework 2
# Load library
library("mlogit")
# Where I store my files
setwd("F:\\Dropbox\\NYU\\2012 Fall\\Choice Models in Operations\\Homework\\Homework2\\")
# part (b)
# Read data
mydata <- read.table("data_frame.txt", sep = "\t", col.names=c( 'id', 'choiceid', 'p1', 'p2'))
# Shape a data.frame in a suitable form for the use of the mlogit function
ml.data <- mlogit.data(mydata, shape="wide", choice="choiceid",
varying=3:4, sep="", alt.levels=c(1,2), id="id")
# V_j = b * p_j
# Estimation by maximum likelihood of the multinomial logit model, with alternative-specific and/or individual specific variables.
ml.results1i <- mlogit(choiceid~p | +0, data = ml.data)
# Result summaries
summary(ml.results1i)
# V_j = a_j + b * p_j with one of the a_j set to zero
ml.results1ii <- mlogit(choiceid~p, data = ml.data, reflevel="1")
summary(ml.results1ii)
# V_j = d_j * p_j
ml.results1iii <- mlogit(choiceid~+0 | +0 | p, data = ml.data)
summary(ml.results1iii)
# Repeat with b = -0.2
mydata <- read.table("data_frame2.txt", sep = "\t", col.names=c( 'id', 'choiceid', 'p1', 'p2'))
ml.data <- mlogit.data(mydata, shape="wide", choice="choiceid",
varying=3:4, sep="", alt.levels=c(1,2), id="id")
# V_j = b * p_j
ml.results2i <- mlogit(choiceid~p | +0, data = ml.data)
summary(ml.results2i)
# V_j = a_j + b * p_j with one of the a_j set to zero
ml.results2ii <- mlogit(choiceid~p, data = ml.data, reflevel="1")
summary(ml.results2ii)
# V_j = d_j * p_j
ml.results2iii <- mlogit(choiceid~+0 | +0 | p , data = ml.data)
summary(ml.results2iii)
# Repeat with b = -0.2 and no-purchase option
mydata <- read.table("data_frame3.txt", sep = "\t", col.names=c( 'id', 'choiceid', 'p0', 'p1', 'p2'))
ml.data <- mlogit.data(mydata, shape="wide", choice="choiceid",
varying=3:5, sep="", alt.levels=c(1,2,3), id="id")
# V_j = b * p_j
ml.results3i <- mlogit(choiceid~p | +0, data = ml.data)
summary(ml.results3i)
# V_j = a_j + b * p_j with one of the a_j set to zero
ml.results3ii <- mlogit(choiceid~p, data = ml.data, reflevel="1")
summary(ml.results3ii)
# V_j = d_j * p_j
ml.results3iii <- mlogit(choiceid~+0 | +0 | p , data = ml.data)
summary(ml.results3iii)
# part (c)
mydata <- read.table("data_frame4.txt", sep = "\t", col.names=c( 'id', 'choiceid', 'p0', 'p1', 'p2'))
ml.data <- mlogit.data(mydata, shape="wide", choice="choiceid",
varying=3:5, sep="", alt.levels=c(1,2,3), id="id")
# V_j = b * p_j
ml.resultsCi <- mlogit(choiceid~p | +0, data = ml.data)
summary(ml.resultsCi)
# V_j = d_j * p_j
ml.resultsCiii <- mlogit(choiceid~+0 | +0 | p , data = ml.data)
summary(ml.resultsCiii)
